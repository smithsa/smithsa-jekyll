<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-10-15T19:08:53-05:00</updated><id>http://localhost:4000/</id><title type="html">Sade Smith</title><subtitle>Software Developer, with 5 years of experience, currently working in the Chicagoland area, specializing in web technologies and skilled in both back-end and front-end development.</subtitle><entry><title type="html">Building a Blog With Jekyll</title><link href="http://localhost:4000/2018/10/15/blog/building-a-blog-with-jekyll/" rel="alternate" type="text/html" title="Building a Blog With Jekyll" /><published>2018-10-15T00:00:00-05:00</published><updated>2018-10-15T00:00:00-05:00</updated><id>http://localhost:4000/2018/10/15/blog/building-a-blog-with-jekyll</id><content type="html" xml:base="http://localhost:4000/2018/10/15/blog/building-a-blog-with-jekyll/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;A few months ago, I decided to convert my personal website, which was a static HTML site, to &lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt;. If you aren’t familiar with Jekyll, it’s a blog-aware static site generator built on Ruby. I wanted to create a blog for my website but wanted a lightweight solution. I considered a few content management systems but ultimately Jekyll came out on top. The decision to convert over to Jekyll was an easy one, and after a few months of using it, certainly a decision I am happy with. In this blog post, I will discuss my experience with the static site generator, it benefits, and how you can get started using it.&lt;/p&gt;

&lt;h2 id=&quot;experience-with-jekyll&quot;&gt;Experience with Jekyll&lt;/h2&gt;

&lt;p&gt;The first requirement I had for my site was that it should be static. If the site was static, then I could easily host it on Github and not have to worry about hosting fees in the future. The next requirement I was for the site to have a blog. However, I didn’t want to have to manually format and a page for each post. I essentially needed a content management system (CMS) for a static site. The first idea I had was to use a CMS like WordPress and access its API writing some reusable code to get posts and it’s metadata. But I didn’t want to have to worry about managing calls to an API which was all too complex for a simple blog. I also realized that for CMSs like WordPress I would have to pay to host an installation of that CMS. So an option like WordPress or Drupal was out of the picture for me. Luckily, I did more research and Jekyll came to my attention — it was a perfect match. A simple, blog-aware, and static site generator was just what I needed. Plus it was an added bonus that &lt;a href=&quot;https://pages.github.com/&quot;&gt;Github Pages&lt;/a&gt; are powered by Jekyll so I could easily deploy the site with Github for free.&lt;/p&gt;

&lt;p&gt;It’s important to note, at this point, I already had a developed static site. I just needed something to manage blog posts for the site. The task at hand was to transfer it into Jekyll. It took less than a day to familiarize myself with its structure and my blog was up and running within a few days. Experience developing countless themes and familiarity with the Liquid templating language, helped me pick up Jekyll quickly. There were some things I had to learn like YAML, formatting in Markdown, and how the plugin system worked. However, they were easy to learn, and I picked those up in no time as well. You certainly don’t need prior experience to get going but it helps!&lt;/p&gt;

&lt;h2 id=&quot;advantages-of-jekyll&quot;&gt;Advantages of Jekyll&lt;/h2&gt;
&lt;p&gt;Before I show you how you can get started, I will list some of the advantages of using Jekyll.&lt;/p&gt;

&lt;h3 id=&quot;free-hosting&quot;&gt;Free Hosting&lt;/h3&gt;
&lt;p&gt;The greatest advantage for me by far. Simply put your Jekyll site in a Github repository and you will have free hosting for your blog. If you are using Github for your version control already, then it makes sense to use it for your free hosting as well – two birds, one stone.&lt;/p&gt;

&lt;h3 id=&quot;speed&quot;&gt;Speed&lt;/h3&gt;
&lt;p&gt;Static files load a lot faster than dynamic files which sometimes have to wait for database queries and API calls. With Jekyll, only the files that are needed are being served.&lt;/p&gt;

&lt;h3 id=&quot;simplicity&quot;&gt;Simplicity&lt;/h3&gt;
&lt;p&gt;You don’t have to worry about databases or bulky user interfaces provided by a CMS. Jekyll only includes what you need.&lt;/p&gt;

&lt;h3 id=&quot;security&quot;&gt;Security&lt;/h3&gt;
&lt;p&gt;The absence of a database eliminates the risk of common security threats such as SQL injections. Your attack surface is drastically reduced.&lt;/p&gt;

&lt;h2 id=&quot;getting-started&quot;&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;Requirements
Ruby version 2.2.5 or above https://www.ruby-lang.org/en/downloads/
Ruby Gems https://rubygems.org/pages/download&lt;/p&gt;

&lt;h2 id=&quot;installation&quot;&gt;Installation&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Install Jekyll and the bundler gem (manages the application’s dependencies)
    &lt;pre&gt;&lt;code&gt; gem install jekyll bundler
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;Create your new Jekyll site
    &lt;pre&gt;&lt;code&gt; jekyll new your-blog-name
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;Navigate to your newly created Jekyll project
    &lt;pre&gt;&lt;code&gt;cd your-blog-name
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;Serve your new Jekyll project on a local server
    &lt;pre&gt;&lt;code&gt;bundle exec jekyll serve
&lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt;Open  &lt;a href=&quot;http://localhost:4000&quot;&gt;http://localhost:4000&lt;/a&gt; in your browser to view your new site.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;configuration&quot;&gt;Configuration&lt;/h2&gt;
&lt;p&gt;Jekyll uses YAML, a human-readable data serialization language, for its configuration file. The file can be found at the root level of your project and it is titled &lt;code&gt;_config.yml&lt;/code&gt;. If you need to reference more options the &lt;a href=&quot;https://jekyllrb.com/docs/configuration/default/&quot;&gt;default configuration&lt;/a&gt; can be found in Jekyll’s documentation. But you can edit the title, email, and description in the file to begin with. Additionally, if you wanted to use a theme or plugin, or just wanted to change the type of Markdown being used you would edit those settings in this file.&lt;/p&gt;

&lt;h2 id=&quot;pages&quot;&gt;Pages&lt;/h2&gt;
&lt;p&gt;Pages in Jekyll are either Markdown or HTML documents and are used for stand-alone content. You can add a page by adding either document types to the root level of your project. If you use a Markdown file, the file will be converted to HTML during its build which can be found in the &lt;code&gt;_site&lt;/code&gt; folder. You can also create subpages by placing your files for your subpages in a folder, titled the parent page. Then create the parent page in a file title &lt;em&gt;index&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;templating-and-layouts&quot;&gt;Templating and Layouts&lt;/h2&gt;
&lt;p&gt;As mentioned previously, &lt;a href=&quot;https://shopify.github.io/liquid/&quot;&gt;Liquid&lt;/a&gt; is used for the templating system. In the pages of the project file, you might see statements wrapped in curly braces. Output statements are surrounded by the double curly braces while logic statements are encapsulated in the curly braces and percent sign. You can add Liquid statement in your pages and layouts.&lt;/p&gt;

&lt;p&gt;Layouts are templates that surround your content, for example, a layout could include your top navigation and footer. The Layouts live the &lt;code&gt;_layouts&lt;/code&gt; directory. Layouts are helpful because you don’t have to copy and paste the code for recurring components of your website (e.g. footer) for every page.&lt;/p&gt;

&lt;p&gt;Additionally, in your layouts and pages, you are given more tools to template pages with Includes. Includes in Jekyll are template parts which live in the &lt;code&gt;_includes&lt;/code&gt; folder. The includes can either be HTML or Markdown files. To use the include you would simply reference its name with the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html lang=&quot;en&quot; class=&quot;no-focus-outline&quot;&amp;gt;
&amp;lt;head lang=&quot;en&quot;&amp;gt;
    &amp;lt;meta charset=&quot;UTF-8&quot;&amp;gt;
&amp;lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot; /&amp;gt;
&amp;lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, maximum-scale=5&quot;&amp;gt;
&amp;lt;link rel=&quot;apple-touch-icon&quot; sizes=&quot;180x180&quot; href=&quot;http://localhost:4000/apple-touch-icon.png&quot;&amp;gt;
&amp;lt;link rel=&quot;icon&quot; type=&quot;image/png&quot; sizes=&quot;32x32&quot; href=&quot;http://localhost:4000/favicon-32x32.png&quot;&amp;gt;
&amp;lt;link rel=&quot;icon&quot; type=&quot;image/png&quot; sizes=&quot;16x16&quot; href=&quot;http://localhost:4000/favicon-16x16.png&quot;&amp;gt;
&amp;lt;link rel=&quot;manifest&quot; href=&quot;http://localhost:4000/site.webmanifest&quot;&amp;gt;
&amp;lt;link rel=&quot;mask-icon&quot; href=&quot;http://localhost:4000/safari-pinned-tab.svg&quot; color=&quot;#555555&quot;&amp;gt;
&amp;lt;meta name=&quot;msapplication-TileColor&quot; content=&quot;#000000&quot;&amp;gt;
&amp;lt;meta name=&quot;theme-color&quot; content=&quot;#ffffff&quot;&amp;gt;
&amp;lt;meta property=&quot;og:description&quot; content=&quot;Software Developer, with 5 years of experience, currently working in the Chicagoland area, specializing in web technologies and skilled in both back-end and front-end development.&quot;&amp;gt;
&amp;lt;meta property=&quot;og:image:width&quot; content=&quot;1052&quot;&amp;gt;
&amp;lt;meta property=&quot;og:image:height&quot; content=&quot;551&quot;&amp;gt;
&amp;lt;meta property=&quot;og:title&quot; content=&quot;Sade Smith&quot;&amp;gt;
&amp;lt;meta property=&quot;og:url&quot; content=&quot;https://sadesmith.com&quot;&amp;gt;
&amp;lt;meta property=&quot;og:image&quot; content=&quot;http://localhost:4000/assets/src/images/og-image.jpg&quot;&amp;gt;
&amp;lt;title&amp;gt;Building a Blog With Jekyll | Sade Smith&amp;lt;/title&amp;gt;
&amp;lt;link href=&quot;https://fonts.googleapis.com/css?family=Poppins:400,600,700&quot; rel=&quot;stylesheet&quot;&amp;gt;
&amp;lt;link href=&quot;https://fonts.googleapis.com/css?family=Montserrat:700&quot; rel=&quot;stylesheet&quot;&amp;gt;
&amp;lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;http://localhost:4000/assets/dist/css/animate.min.css&quot;&amp;gt;
&amp;lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;http://localhost:4000/assets/dist/css/bootstrap.min.css&quot;&amp;gt;
&amp;lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;http://localhost:4000/assets/dist/css/ionicons.min.css&quot;&amp;gt;
&amp;lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;http://localhost:4000/assets/dist/css/style.min.css&quot;&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
&amp;lt;div id=&quot;loading&quot;&amp;gt;&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;posts&quot;&gt;Posts&lt;/h2&gt;
&lt;p&gt;The posts of your Jekyll site live in the &lt;code&gt;_posts&lt;/code&gt; folder. Jekyll states that typically posts are written in Markdown but HTML is also supported. I exclusively use Markdown, I find that it is easiest to maintain. If you need help in formatting Markdown, I’ve found this &lt;a href=&quot;https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet&quot;&gt;Markdown cheatsheet&lt;/a&gt; on github created by &lt;a href=&quot;https://crypti.cc/&quot;&gt;Adam Pritchard&lt;/a&gt; to be a great resource. Each file name should follow this specific format where ‘YEAR’ is the four-digit year number, &lt;code&gt;MONTH&lt;/code&gt; and &lt;code&gt;DAY&lt;/code&gt; are two digit numbers reflecting each respectively, and Markup is the file extension :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;YEAR-MONTH-DAY-title.MARKUP
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At the top of every post will be YAML front matter, which Jekyll uses for maintaining metadata throughout the site (You might have noticed it on the pages). All posts must use this format for its metadata. The most basic front matter will include the layout and title.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;layout: post
title:  &quot;Welcome to Jekyll!&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Following the post’s metadata is the content of the post.&lt;/p&gt;

&lt;h2 id=&quot;assets-and-static-files&quot;&gt;Assets and Static Files&lt;/h2&gt;
&lt;p&gt;Lastly, Jekyll provides built-in support for Sass and CoffeScript. Sass files should live in a &lt;code&gt;_sass&lt;/code&gt; folder. The stylesheets will be output to a &lt;code&gt;css&lt;/code&gt; folder when the build runs. To use CoffeeScript a gem is required. For more information you can read &lt;a href=&quot;https://jekyllrb.com/docs/assets/&quot;&gt;Jekyll’s documentation on how to use Sass and CoffeScript&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Alternatively, you can serve your JavaScript and CSS as static files. Static files can be PDFs, Javascript and CSS files, images, etc. Any content that does not need to be rendered. Static files are accessible via Liquid: &lt;code&gt;site.static_files&lt;/code&gt;. To serve your static files, you can use &lt;code&gt;http://localhost:4000&lt;/code&gt; and follow it by the path to the file as well.&lt;/p&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;Jekyll is easy to get started with and provides you with a lightweight alternative to using a CMS if you are building a blog. You get speed, simplicity, better security than a CMS, and an added bonus of free hosting with Jekyll! Converting over to Jekyll for my website was a great decision and one I do not regret a bit because of its ease of use and benefits. I would recommend it to anyone who wants to create a blog.&lt;/p&gt;</content><author><name></name></author><category term="jekyll" /><category term="static site generator" /><category term="web" /><summary type="html">A few months ago, I decided to convert my personal website, which was a static HTML site, to Jekyll. If you aren’t familiar with Jekyll, it’s a blog-aware static site generator built on Ruby. I wanted to create a blog for my website but wanted a lightweight solution. I considered a few content management systems but ultimately Jekyll came out on top.</summary></entry><entry><title type="html">10 Tips for Web Accessibility (Part 2)</title><link href="http://localhost:4000/2018/08/12/blog/10-tips-for-web-accessiblity-part-2/" rel="alternate" type="text/html" title="10 Tips for Web Accessibility (Part 2)" /><published>2018-08-12T00:00:00-05:00</published><updated>2018-08-12T00:00:00-05:00</updated><id>http://localhost:4000/2018/08/12/blog/10-tips-for-web-accessiblity-part-2</id><content type="html" xml:base="http://localhost:4000/2018/08/12/blog/10-tips-for-web-accessiblity-part-2/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In the previous article, &lt;a href=&quot;http://www.sadesmith.com/2018/08/05/blog/10-tips-for-web-accessiblity-part-1/&quot;&gt;“10 Tips for Web Accessibility (Part 1)”&lt;/a&gt;, we covered the first five tips I have for creating accessible websites. In this post, I will continue to list off the remaining five tips. In the last five tips, I will cover skip links, ARIA, form labels, and font sizes.&lt;/p&gt;

&lt;h2 id=&quot;6-create-skip-links&quot;&gt;6. Create Skip Links&lt;/h2&gt;

&lt;p&gt;Skip links allow users who are not using a mouse and are tabbing through the page to bypass links in sections like the navigation and go directly to the main content of the page. In addition, these links can save time for those who are using a screen reader because the reader will want to read aloud links in the navigations it traverses. So it is recommended that skip links are created. They should be at the top of your tab index and not appear to users who are not tabbing or using a screen reading device. &lt;a href=&quot;https://jonkantner.com/&quot;&gt;John Kantner&lt;/a&gt; offers a great skip link example below:&lt;/p&gt;

&lt;iframe height=&quot;265&quot; scrolling=&quot;no&quot; title=&quot;Skip Link Navigation&quot; src=&quot;//codepen.io/jkantner/embed/zqJJdW/?height=265&amp;amp;theme-id=0&amp;amp;default-tab=html,result&amp;amp;embed-version=2&quot; frameborder=&quot;no&quot; allowtransparency=&quot;true&quot; allowfullscreen=&quot;true&quot; style=&quot;width: 100%;&quot;&gt;See the Pen &lt;a href=&quot;https://codepen.io/jkantner/pen/zqJJdW/&quot;&gt;Skip Link Navigation&lt;/a&gt; by Jon Kantner (&lt;a href=&quot;https://codepen.io/jkantner&quot;&gt;@jkantner&lt;/a&gt;) on &lt;a href=&quot;https://codepen.io&quot;&gt;CodePen&lt;/a&gt;.
&lt;/iframe&gt;

&lt;h2 id=&quot;7-use-aria-attributes-when-appropriate&quot;&gt;7. Use ARIA Attributes When Appropriate&lt;/h2&gt;
&lt;p&gt;ARIA attributes communicate with assistive technology devices the role (i.e. user interface pattern), property (i.e. label name) , and state (i.e. pressed) of your HTML elements. When native HTML elements will not meet your needs and further modification is required, then you should use ARIA. They provide semantics to elements when they are missing. Using ARIA is most useful in scenarios where you need to (1) signify a landmark such as a search area or navigation, (2) when you update content dynamically, (3) add keyboard accessibility, and (4) use custom complex UI controls. It’s important to note that ARIA modifies the accessibility tree but not the DOM itself thus does not change its behavior. Lastly use ARIA with discretion, you should avoid redundancy of defining an element’s role, for example you do not need to use an ARIA attribute of radio (&lt;code&gt;role=”radio”&lt;/code&gt;) on an input with the type radio (&lt;code&gt;&amp;lt;input type=”radio”&amp;gt;&lt;/code&gt;). In addition, elements should not have aria attributes that interfere with their semantics (list of attributes allowed on each HTML element.)[https://www.w3.org/TR/html-aria/#docconformance] (For more information on ARIA, Mozilla offers a great comprehensive (ARIA guide)[https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA] with examples.&lt;/p&gt;

&lt;h2 id=&quot;8-use-aria-pressed-attribute-for-active-states&quot;&gt;8. Use ARIA Pressed Attribute for Active States&lt;/h2&gt;
&lt;p&gt;There are instances where you need to communicate the active state of a button or link. For example, navigation menus often have an active state to signify a current page or tabbed content usually has an active tab to indicate the current content being displayed. Often, an active class is used in these instances. However, classes are not in the accessibility tree and screen readers are unable to read classes thus unable to detect the active state. To solve this issue, you can use the ARIA attributes &lt;code&gt;aria-pressed&lt;/code&gt; and &lt;code&gt;&amp;lt;aria-label&lt;/code&gt;. When the active button is pressed you can set the &lt;code&gt;aria-pressed&lt;/code&gt; attribute to true, false otherwise. You can also give the active button or link a label of the current page with the ARIA attribute &lt;code&gt;&amp;lt;aria-label&lt;/code&gt;. Additionally, you can style the CSS &lt;code&gt;[aria-pressed=”true”]&lt;/code&gt; selector for those elements instead of the active class. See the following example below: &lt;/p&gt;

&lt;iframe height=&quot;265&quot; scrolling=&quot;no&quot; title=&quot;Accessible Current Section Example&quot; src=&quot;//codepen.io/smithsa/embed/XBPqae/?height=265&amp;amp;theme-id=0&amp;amp;default-tab=html,result&amp;amp;embed-version=2&quot; frameborder=&quot;no&quot; allowtransparency=&quot;true&quot; allowfullscreen=&quot;true&quot; style=&quot;width: 100%;&quot;&gt;See the Pen &lt;a href=&quot;https://codepen.io/smithsa/pen/XBPqae/&quot;&gt;Accessible Current Section Example&lt;/a&gt; by Sade Smith (&lt;a href=&quot;https://codepen.io/smithsa&quot;&gt;@smithsa&lt;/a&gt;) on &lt;a href=&quot;https://codepen.io&quot;&gt;CodePen&lt;/a&gt;.
&lt;/iframe&gt;

&lt;h2 id=&quot;9-always-use-labels-for-form-inputs&quot;&gt;9. Always Use Labels for Form Inputs&lt;/h2&gt;
&lt;p&gt;Forms built improperly can be difficult to navigate if a user is using a screen reader or keyboard, making it difficult for those with disabilities to carry out the task of filling out a form. One pain point is the lack of description provided for form inputs. All form fields should include a label tag to accurately describe what is required for the form field. Often, a design does not include a label but a placeholder instead. However, developers should not use placeholders in lieu of labels. An alternative to just using placeholders is to use float labels, see the example below. You can even use the &lt;code&gt;.a11y-hidden&lt;/code&gt; visibility code we covered in &lt;a href=&quot;http://www.sadesmith.com/2018/08/05/blog/10-tips-for-web-accessiblity-part-1/&quot;&gt;part 1&lt;/a&gt;.&lt;/p&gt;

&lt;iframe height=&quot;265&quot; scrolling=&quot;no&quot; title=&quot;Float Label Example&quot; src=&quot;//codepen.io/smithsa/embed/GBdXQN/?height=265&amp;amp;theme-id=0&amp;amp;default-tab=css,result&amp;amp;embed-version=2&quot; frameborder=&quot;no&quot; allowtransparency=&quot;true&quot; allowfullscreen=&quot;true&quot; style=&quot;width: 100%;&quot;&gt;See the Pen &lt;a href=&quot;https://codepen.io/smithsa/pen/GBdXQN/&quot;&gt;Float Label Example&lt;/a&gt; by Sade Smith (&lt;a href=&quot;https://codepen.io/smithsa&quot;&gt;@smithsa&lt;/a&gt;) on &lt;a href=&quot;https://codepen.io&quot;&gt;CodePen&lt;/a&gt;.
&lt;/iframe&gt;

&lt;h2 id=&quot;10-use-relative-font-sizes&quot;&gt;10. Use Relative Font Sizes&lt;/h2&gt;
&lt;p&gt;The World Wide Consortium recommends that your fonts use relative font units such as em, percentages, or rem. This allows user agents to scale the font sizes more effectively if needed. As a rule of thumb, the font size needs to be able to scale to at least 200% and still be visible and legible to the user. Modern browsers are usually able to meet this requirement even with fixed font units like pixels and pt but it is generally a good practice to use relative units.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The web has become an invaluable resource to many and an integral part of our everyday lives. It’s important that the web is a resource available to all, including those who are differently abled. It should provide equal access and opportunity. With this in mind, developers should strive to develop applications adhering to fundamental accessibility best practices, putting the user experience of all users at the forefront of their mind. Using these tips as a baseline will help ensure that everyone has the same access. For more information on the topic of web accessibility, I recommend reading the &lt;a href=&quot;https://www.w3.org/WAI/WCAG21/quickref/?versions=2.0&quot;&gt;WCAG quick reference&lt;/a&gt; provided by the World Wide Consortium and looking into the &lt;a href=&quot;https://www.google.com/accessibility/for-developers.html&quot;&gt;accessibility resources&lt;/a&gt; that Google provides for developers on accessibility.&lt;/p&gt;</content><author><name></name></author><category term="accessibility" /><category term="a11y" /><category term="wcag" /><summary type="html">In the previous article, “10 Tips for Web Accessibility (Part 1)” we covered the first five tips I have for creating accessible websites. In this post, I will continue to list off the remaining five tips. In the last five tips, I will cover skip links, ARIA, form labels, and font sizes.</summary></entry><entry><title type="html">10 Tips for Web Accessibility (Part 1)</title><link href="http://localhost:4000/2018/08/05/blog/10-tips-for-web-accessiblity-part-1/" rel="alternate" type="text/html" title="10 Tips for Web Accessibility (Part 1)" /><published>2018-08-05T00:00:00-05:00</published><updated>2018-08-05T00:00:00-05:00</updated><id>http://localhost:4000/2018/08/05/blog/10-tips-for-web-accessiblity-part-1</id><content type="html" xml:base="http://localhost:4000/2018/08/05/blog/10-tips-for-web-accessiblity-part-1/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The benefits of developing accessible websites undoubtedly outweigh the costs. First and foremost, all potential users are able to use your web application. Users with disabilities will be able to access information and perform tasks just as those without disabilities. Secondly, accessibility (a11y) best practices share similar practices with other web related best practices such as search engine optimization (SEO) and usability standards. Following the best practices for accessibility means you will be following the best practices of the web. In this two-part series, I will be giving some practical development tips based on recommendations from the Web Content Accessibility Guidelines (WCAG) that you can use to develop more accessible websites.&lt;/p&gt;

&lt;h2 id=&quot;1-use-native-html-elements-properly&quot;&gt;1. Use Native HTML Elements Properly&lt;/h2&gt;

&lt;p&gt;It is important that you use native HTML elements because they have accessibility benefits built-in. For example, using the button tag allows a button to be automatically indexed with the tab button and activated using the keyboard. If you were to not use the button tag and create your own button with a custom tag or div these benefits would not be afforded to you. Don’t recreate the wheel unless you have an extremely good reason. If you decide to create your own custom elements be sure to create keyboard accessibility and provide a tabindex attribute of 0.&lt;/p&gt;

&lt;p&gt;In addition, your HTML should be written in a way that conveys the semantics of a given page. Good semantics help assistive technology devices, such as screen readers, perform their jobs by giving them a map of what is being parsed. You should consider using HTML5 semantic elements like header, nav, footer, aside, article, and section to structure your pages. Also, strive to use and structure these HTML elements correctly. Inconsistencies or improper structuring of your HTML can confuse and throw screen readers off.&lt;/p&gt;

&lt;h2 id=&quot;2-use-appropriate-html-heading-tags&quot;&gt;2. Use Appropriate HTML Heading Tags&lt;/h2&gt;
&lt;p&gt;Along similar lines of the tip #1, you should use the appropriate HTML heading tag and ensure the correct order. With &lt;code&gt;h1&lt;/code&gt; being the highest section level heading and &lt;code&gt;h6&lt;/code&gt; being the lowest. In the scenarios that your designs do not contain a heading, you can add a header that describes the sections succinctly and then style the heading so that it does not visually appear on the screen. Adding heading tags allows assistive technology devices to understand what is on the page and are good for but also SEO. I like to use a special class for these instances (see example below).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-css&quot;&gt;.a11y-hidden{
	position: absolute;
	z-index: -9999;
	width:1px;
	height: 1px;
	font-size: 0;
	border: 0;
	padding: 0;
	margin: 0;
	overflow: hidden;
	white-space: nowrap;
	clip: rect(0,0,0,0);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;3-use-background-images-for-decorative-images&quot;&gt;3. Use Background Images for Decorative Images&lt;/h2&gt;
&lt;p&gt;Some designs have images that don’t convey any information to the user and are there for style or decorative purposes. These images should be displayed using the CSS &lt;code&gt;background-image&lt;/code&gt; property if possible. If you determine that an image tag is needed, then make sure that the &lt;code&gt;alt&lt;/code&gt;  attribute is empty so that screen readers can skip over reading the image.&lt;/p&gt;

&lt;h2 id=&quot;4-dont-remove-css-outline&quot;&gt;4. Don’t Remove CSS Outline&lt;/h2&gt;
&lt;p&gt;There are times when you create a link or a button and see a blue glowing outline on your element. Sometimes it clashes with the overall design, so to remove it developers change the outline CSS property to none. It’s a big accessibility no-no. It makes it difficult for those who do not use a mouse to see where they are currently at on a page if they are for instance tabbing through. In the cases, that you do decide that you can’t have that blue glow, go ahead and use &lt;code&gt;outline: none&lt;/code&gt; in your CSS but also style the focused (:focus) state of the element in a way that clearly shows that it is selected. It is a good practice to style your focus states the same as your hover state.&lt;/p&gt;

&lt;h2 id=&quot;5-always-use-a-meta-viewport-tag&quot;&gt;5. Always Use a Meta Viewport Tag&lt;/h2&gt;
&lt;p&gt;Using a meta viewport tag is probably the easiest tip in this post to implement. If your website is missing this tag, mobile devices will render the pages at desktop widths, then scale the page for the mobile device. So the meta viewport tag will ensure that the page fits the width of the device. Google recommends using the following meta tag in the head of your pages:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-html&quot;&gt;&amp;lt;head&amp;gt;
  ...
  &amp;lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=5&quot;&amp;gt;
  ...
&amp;lt;/head&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;wrapping-it-up&quot;&gt;Wrapping It Up&lt;/h2&gt;
&lt;p&gt;As you can see, these are very simple tips to implement in your website to make them more accessible and provide an overall improvement. The best part, there’s More! Stay tuned for part 2, where we will continue going over practical tips for developing accessible websites. Getting into more accessibility principles, I will be touching upon ARIA, skip links, form labels, and font sizes.&lt;/p&gt;</content><author><name></name></author><category term="accessibility" /><category term="a11y" /><category term="wcag" /><summary type="html">Following the best practices for accessibility means you will be adhering to the best practices of the web. In this two-part series, I will be giving some practical development tips based on recommendations from the Web Content Accessibility Guidelines (WCAG) that you can use to develop more accessible websites.</summary></entry><entry><title type="html">3 Browser APIs to be Excited About</title><link href="http://localhost:4000/2018/07/18/blog/3-browser-apis-to-be-excited-about/" rel="alternate" type="text/html" title="3 Browser APIs to be Excited About" /><published>2018-07-18T00:00:00-05:00</published><updated>2018-07-18T00:00:00-05:00</updated><id>http://localhost:4000/2018/07/18/blog/3-browser-apis-to-be-excited-about</id><content type="html" xml:base="http://localhost:4000/2018/07/18/blog/3-browser-apis-to-be-excited-about/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Each year web technologies push the boundaries of what was thought possible. The gap between native and web applications steadily narrows as browsers introduce new web/browser application programming interfaces (APIs). Evidence of this is seen in the standardization of browser APIs like Geolocation and AmbientLightSensor. These APIs remove capability barriers by providing access to device hardware. Additionally, we can see APIs like Web Storage and IndexedDB adding a performance boost by storing data on the client-side. The best part is that the list of browser APIs keeps growing, and in turn, enhancing the capability of the web. It’s certainly an exciting time to be developing for the web!&lt;/p&gt;

&lt;p&gt;In this post, we will be exploring some of these APIs improving the everyday web experience. I will be giving an overview of five exciting browser APIs you should know about. For each API, we will go over what the API does, potential use cases, and current browser support. Developers should consider implementing these new technologies in their web applications once browsers adopt and ship them. Until then, be sure to feature detect if you decide to use these APIs sooner than later.&lt;/p&gt;

&lt;h2 id=&quot;webshare-api&quot;&gt;Webshare API&lt;/h2&gt;
&lt;p&gt;Currently, there isn’t a standard way to access the share dialog of native devices using the web. The &lt;a href=&quot;https://developers.google.com/web/updates/2016/09/navigator-share&quot;&gt;WebShare API&lt;/a&gt; fixes this problem and allows your web applications to invoke native device’s share dialog. Developers can access the API through the navigator object, calling the share() method.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;    navigator.share()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It makes sharing easier for users and gives them more control over how they would like to share information from the web. Potential use cases for the Webshare API are for sites that currently use share buttons to share content (i.e.: blogs and sites that have a lot of short-form media like images). If you want to use this API, simply provide the share method with an object that has the following properties listed below in the code example. At a minimum, the properties of text and URL are required. Another requirement is that the website you share must use HTTPS. Additionally, the Web Share API is promised-based so you can use promises and catch errors with this method.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;	navigator.share({
		title: ‘Sade Smith’,
		text: ’3 Browser APIs you should be excited about’,
		url: '[https://sadesmith.com](https://sadesmith.com/),
	})
	.then(() =&amp;gt; console.log('Successful share'))
	.catch((error) =&amp;gt; console.log('Error sharing', error
	));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Below you can see the functionality of the API in action courtesy of &lt;a href=&quot;[https://paul.kinlan.me/](https://paul.kinlan.me/)&quot;&gt;Paul Kinlan&lt;/a&gt; from Google.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/lhUzYxCvWew&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;small&gt;Payment Request API, courtesy of Google Chrome Developers&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;I know what you are thinking about: browser support, right? The only browsers that offer full support are Chrome 61 android and Opera 48 and Webkit is considering adding support as well. It will be interesting to see if other browsers move to adopt this API. If there is a wider adoption, then that would mean the web would be a step closer to closing the gap between the web and native. For now, if you decide to use this API, you should feature-detect to ensure that the API is available on the user’s platform.strong text&lt;/p&gt;

&lt;h2 id=&quot;payment-request-api&quot;&gt;Payment Request API&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&quot;https://developers.google.com/web/fundamentals/payments/&quot;&gt;Payment Request API&lt;/a&gt; aims to make the traditional tedious checkout process on website obsolete by storing users billing information in the browser and presenting a consistent, secure and user-friendly interface regardless of payment method. Checkout forms are notoriously long and repetitive across sites and filling out these forms on mobile devices are even more of a headache. This API streamline the checkout process and makes the checkout flow a lot shorter. Now with the Payment Request API, you can checkout with a few click and keyboard is not needed at all. Amazing, right? So let’s talk about how it works.&lt;/p&gt;

&lt;p&gt;The browser will securely store and save your information for purchases and then send it to the merchant. (the address in this) The merchant then can send back options for shipping. The only required input from the user would is the CVC. Once the user confirms the payment, the data is securely bundled and sent to the merchant. Once the browser determines that the accepted payment methods for the site and the methods on the device are compatible, the browser will display the payments UI. The user then selects the payment method and authorized the transaction. The data the user entered and has stored (i.e. card number, CVC, card expiration date) is bundled and sent to the merchant site.&lt;/p&gt;

&lt;p&gt;It’s important to note that this is not a new payment method itself. It does not replace payment processors like Stripe and Braintree. Nor does it interact directly with payment processors. The API is simply a way to send user’s payment and shipping information to merchants to allow for a seamless and painless checkout experience on any browser, device, or platform. So it’s vendor agnostic, it does not matter what payment processing service you use.&lt;/p&gt;

&lt;p&gt;The use cases for this API are any websites that sell services or products. E-ccommerce sites can definitely use this API to their advantage. The main benefit is that it can increase conversion rates for online businesses by decreasing the drop-off that happens during the checkout process. The API removes the friction involved in making a purchase, thus making it more likely a user will complete the process. If you choose to use this API, your website must be served over a secure connection (use HTTPS).&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/hmqZxP6iTpo&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;small&gt;Payment Request API, courtesy of Google Chrome Developers&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;The Payment Request API is currently supported in Chrome, Safari, and Edge. Additionally, Firefox is working on an implementation. It is a W3C standard candidate so hopefully, we see it being adopted by more browser engines in the future.&lt;/p&gt;

&lt;h2 id=&quot;service-worker-api&quot;&gt;Service Worker API&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://developers.google.com/web/ilt/pwa/introduction-to-service-worker&quot;&gt;Service workers&lt;/a&gt; are web workers that run in the background of your browser, separate from the main thread, running asynchronously. It is independent of the website itself so it does not have access to the DOM. Service workers are essentially a JavaScript file that has control of the associated website’s network requests and cache resources. In addition, the service worker can receive push messages for a server when the web application is not open so notifications can be pushed to the user without the website being opened. They can be thought of as a proxy server that positioned between a web application, the browser, and the network (when a network can be accessible).&lt;/p&gt;

&lt;p&gt;The Service Worker API is immensely important to the web because it allows for devices to access content when they are offline or have limited connectivity and allows websites to send push notifications even when the site is not open. These two features were previously only capable in native applications. Service workers combined with other APIs help the web get closer to native mobile apps by providing features native apps previously only held. Being able to access content from the web offline or with a poor connection is big!&lt;/p&gt;

&lt;p&gt;Using a service worker, requires you to register it in your website’s Javascript and serve your application over a secure connection. Once the service worker is registered, the browser will start the installation step in the background. The next step is activation, where the service worker can finish setup or clean related resources (for example, cleaning older caches). You can find more information on how to use the Service Worker API from &lt;a href=&quot;[https://developer.mozilla.org/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers](https://developer.mozilla.org/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers)&quot;&gt;Mozilla’s service worker documentation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The most obvious use case would be to use this API for offline experiences. The Service Worker API is being used in progressive web applications (PWAs), which are regular websites which appear to have a native feel and offer an immersive experience like native apps. Service workers allow these web applications to run offline, a feature only mobile applications used to have. As a result, PWAs are indistinguishable from native mobile applications to the average user.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/U35B31dBvBk&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;small&gt;Demo, courtesy of &lt;a href=&quot;https://github.com/davidnguyen179&quot;&gt;Dung Nguyen&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;There is good news in terms of browser support for service workers! Most of the major browsers support service workers, that includes Edge, Chrome, Safari, and Firefox. You can find more detailed information at &lt;a href=&quot;[https://jakearchibald.com/](https://jakearchibald.com/)&quot;&gt;Jake Archibald’s&lt;/a&gt; site named &lt;a href=&quot;[https://jakearchibald.github.io/isserviceworkerready/](https://jakearchibald.github.io/isserviceworkerready/)&quot;&gt;“Is Service Worker Ready”&lt;/a&gt; but it is definitely a good idea to start using the API now&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;With these new browser APIs, there has never been a better time to be developing for the web in my opinion. The list could continue: Web Bluetooth, WebVR, Shape Detection, WebAssembly, and Credential Management are APIs to keep your eye on as well. Without a doubt, the web as a platform remains a good bet and is progressively growing stronger. These APIs are worth everyone’s attention.&lt;/p&gt;</content><author><name></name></author><category term="javascript" /><category term="browser" /><category term="web share" /><category term="web bluetooth" /><category term="service workers" /><category term="payment requests" /><category term="pwas" /><category term="apis" /><summary type="html">The gap between native and web applications steadily narrows as browsers introduce new web/browser application programming interfaces (APIs). Evidence of this is seen in the standardization of browser APIs like Geolocation and AmbientLightSensor. These APIs remove capability barriers by providing access to device hardware.</summary></entry><entry><title type="html">Scraping Client Side Rendered Data with Python and Selenium</title><link href="http://localhost:4000/2018/06/15/blog/scraping-client-side-rendered-data-with-python-and-selenium/" rel="alternate" type="text/html" title="Scraping Client Side Rendered Data with Python and Selenium" /><published>2018-06-15T00:00:00-05:00</published><updated>2018-06-15T00:00:00-05:00</updated><id>http://localhost:4000/2018/06/15/blog/scraping-client-side-rendered-data-with-python-and-selenium</id><content type="html" xml:base="http://localhost:4000/2018/06/15/blog/scraping-client-side-rendered-data-with-python-and-selenium/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Scraping data from websites often offers a way to automate tedious tasks and improve productivity. However, many people run into issues when the content of a website is generated on the client side as opposed to the server-side. For instance, content can not be retreived with just a HTTP request for websites that utilize AJAX to generate it’s content. A web scrapper using only server-side requests would be unable to scrape the data of such a site because the HTML of the page does not load until the javascript of the site can be executed. Since the Javascript can only be executed on the client side, a request from the page would not include it’s dynamic content.&lt;/p&gt;

&lt;p&gt;To solve this problem, you can use a browser automation tool such as Selenium or PhantomJs in combination with your web scraper script. Using a browser automation tool, the HTML is able to be generated and thus read and parsed. In this tutorial, I will be showing you how to write a basic script to scrape client-side rendered content with Python and Selenium.&lt;/p&gt;

&lt;p&gt;Remember before you scrape content or data from websites, ensure that you have legal rights to do so, read the site’s terms of service agreement to see if scraping is allowed, and ensure that an alternative method for to retrieve the data does not exist, for example an API. In addition, check the robots.txt file and follow the rules for how frequently you are allowed to request pages and what pages are allowed to be scraped.&lt;/p&gt;

&lt;p&gt;The Python Selenium library includes a HTML tree parser but we will use Selenium to load the page’s content and BeautifulSoup to parse the HTML, since BeautifulSoup is Python’s most popular parser.&lt;/p&gt;

&lt;h2 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Python 2.7 programming environment available here (&lt;a href=&quot;https://www.python.org/downloads/&quot;&gt;https://www.python.org/downloads/&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;MacOS or Linux Environment&lt;/li&gt;
  &lt;li&gt;Virtualenv available here (&lt;a href=&quot;https://pypi.org/project/virtualenv/&quot;&gt;https://pypi.org/project/virtualenv/&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;pip, package manager for available here python (&lt;a href=&quot;https://pip.pypa.io/en/stable/installing/&quot;&gt;https://pip.pypa.io/en/stable/installing/&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;virtual-environment-setup&quot;&gt;Virtual Environment Setup&lt;/h2&gt;

&lt;p&gt;Before we start writing the script, we will first set up a virtual environment. Let’s first create a directory for the project called simple-scrapper and navigate to the directory.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-terminal&quot;&gt;    mkdir simple-scrapper
    cd simple-scrapper
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can create the virtual environment and activate the environment with the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-terminal&quot;&gt;    virtualenv venv
    source venv/bin/activate
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;installing-python-libraries&quot;&gt;Installing Python Libraries&lt;/h2&gt;

&lt;p&gt;Next, we can install all the python modules and libraries we will need for the script with pip. We will need the selenium python bindings, BeatifulSoup4, and the requests library.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;    pip install selenium
    pip install BeautifulSoup4
    pip install requests
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;downloading-selenium-driver&quot;&gt;Downloading Selenium Driver&lt;/h2&gt;

&lt;p&gt;Now that we have all our libraries installed, we should download a driver for Selenium. The driver is required for Selenium to interface the browser you choose to use. For our purposes, we will use Chrome as our browser. You can download the latest release of the Chrome driver here: http://chromedriver.chromium.org/downloads. Download the appropriate zip file for your operating system, unzip the file, and you should find an executable file named “chromedriver.” Put this file at the root of the “simple-scrapper” folder we just created.&lt;/p&gt;

&lt;h2 id=&quot;the-web-scraping-script&quot;&gt;The Web Scraping Script&lt;/h2&gt;

&lt;p&gt;We are now ready to start writing the scraper. Let’s create a python file in at the root of the folder “simple-scraper” called “scrapper.py.”&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-terminal&quot;&gt;    touch scrapper.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Open the file with your preferred text editor and let’s start writing the code to scrape a web page. For our purposes, I have created a basic page to scrape that has client-side rendered HTML. You can find the example file here: &lt;a href=&quot;http://sadesmith.com/examples/simple-scrapper/index.html&quot; target=&quot;_blank&quot;&gt;http://sadesmith.com/examples/simple-scrapper/index.html&lt;/a&gt;. Lets quickly examine the content of the page. The page simply lists the names of basketball players on the 2018 Golden State Warriors Roster — there is one header and an unordered list. Our goal will be simple, scrape all the names of the roster and print them out once collected.&lt;/p&gt;

&lt;p&gt;The first task will be to load the webpage using the driver we just downloaded. We will need to tell the WebDriver where the driver is located by setting the executable path on the Chrome class. Then we can request the webpage by using the get method of the driver.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;    import os
    from selenium import webdriver

    driver = webdriver.Chrome(executable_path= os.path.abspath('')+'/chromedriver')
    url = &quot;http://www.sadesmith.com/examples/simple-scrapper/index.html&quot;
    driver.get(url)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, we will need to tell the WebDriver to wait a few seconds before parsing the page. We will import the time module and use the sleep method. We will give the method the value of 3, thus the wait time will be 3 seconds.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;    import os
    from selenium import webdriver
    import time

    driver = webdriver.Chrome(executable_path= os.path.abspath('')+'/chromedriver')
    url = &quot;http://www.sadesmith.com/examples/simple-scrapper/index.html&quot;
    driver.get(url)
    time.sleep(3)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We are ready to parse but before we do that let’s import beautiful soup.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;    from bs4 import BeautifulSoup
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can grab the content we need to parse. With the WebDriver loading the page, we can now view content loaded client-side. WebDriver’s page_source will return the source code of the DOM as a string. We can use BeautifulSoup to parse the HTML string, with its HTML parser.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;    page_html = driver.page_source
    bsoup = BeautifulSoup(page_html, 'html.parser')
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With the BeautifulSoup object, we can then use the library to its full extent. If you are unfamiliar with BeautifulSoup you can find more documentation here about how to parse: https://www.crummy.com/software/BeautifulSoup/bs4/doc/. For our example, we know that all the names on the Warrior’s rosters are in an unordered list, in list item tag with the class name of “name”. So we can grab all list item elements with the class attribute name then loop through them print them out.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;    player_names = bsoup.findAll('li', attrs={'class': 'name'});
    for player_name in player_names:
      print player_name.text
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;wrapping-it-all-up&quot;&gt;Wrapping it all up&lt;/h2&gt;

&lt;p&gt;We are done with the simple scrapper and your file should now look this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;    import os
    from selenium import webdriver
    import time
    from bs4 import BeautifulSoup

    driver = webdriver.Chrome(executable_path= os.path.abspath('')+'/chromedriver')
    driver.get(url)
    time.sleep(3)

    page_html = driver.page_source
    bsoup = BeautifulSoup(page_html, 'html.parser')

    player_names = bsoup.findAll('li', attrs={'class': 'name'});
    for player_name in player_names:
        print player_name.text
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let’s run the project in the terminal! Make sure your current working directory is “simple-scrapper” and run the script.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-terminal&quot;&gt;    python scrapper.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If everything went well, you should see the names of the players on the 2018 Golden State Warriors printed in your terminal screen. We have accomplished our objective! Via our simple web scraper script, we were able to scrape HTML that was generated on the client-side using Selenium and Python.&lt;/p&gt;</content><author><name></name></author><category term="python" /><category term="selenium" /><category term="automation" /><category term="tutorial" /><category term="web scraping" /><summary type="html">Scraping data from websites often offers a way to automate tedious tasks and improve productivity. However, many people run into issues when the content of a website is generated on the client side as opposed to the server-side.</summary></entry><entry><title type="html">Overview of the HTTP/2 Protocol</title><link href="http://localhost:4000/2018/06/02/blog/overview-of-the-http2-protocol/" rel="alternate" type="text/html" title="Overview of the HTTP/2 Protocol" /><published>2018-06-02T00:00:00-05:00</published><updated>2018-06-02T00:00:00-05:00</updated><id>http://localhost:4000/2018/06/02/blog/overview-of-the-http2-protocol</id><content type="html" xml:base="http://localhost:4000/2018/06/02/blog/overview-of-the-http2-protocol/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In 2015, the HyperText Transfer Protocol (HTTP) underwent a major revision when HTTP/2 became officially standardized. With the protocol’s last major update being in 1999 (HTTP/1.1), it was a much needed upgrade. The previous version of the protocol, HTTP/1.1, proved to posses numerous limitations for most modern websites. The average HTTP requests per page have risen dramatically overtime as well as page size. Simply put, HTTP/1.1 was developed to handle websites of its time and not of today. These limitations later led developers to use HTTP/1.1 in ways it was not meant to be used, causing developers to create workarounds which developed into best practices. For example, with HTTP/1.1 a client only has a limited number of TCP connections (6 connections) to a server, and each request requires one of those connections. With limited connections a request must wait for another to finish before being processed (HOL Blocking), resulting in a bottleneck for websites retrieving resources, slowing down performance. To solve this problem, file concatenation, image sprites, domain sharding, using gzip, and resource inlining became workarounds and best practices for this particular issue of HOL Blocking. These solutions proved to be hacks, not really solving the issue at hand, which was really at the protocol level.&lt;/p&gt;

&lt;p&gt;In 2009, Google recognized these issues for their own operations of transporting web content and began working on an internal project called SPDY. SPDY was a network protocol that offered solutions to many of HTTP/1.1’s shortcomings, ofadfering addresings issues o web security and improved page load latency. This protocol would later become the foundation of HTTP/2.&lt;/p&gt;

&lt;p&gt;Fast forward to 2018, SPDY is deprecated and HTTP/2 is the new current version of HTTP with adoption increasing. HTTP/2 resolves the problems with HTTP/1.1 at the protocol level and provides faster performance for a website. The new protocol is backwards compatible and has the same semantics as HTTP/2, but improves how data is sent and what data is sent. The core features of HTTP/2 are multiplexing, binary framing, header compression, prioritization, and server push. With the update, many of the best practices developers utilize are invalidated and are detrimental to performance. These new core features of HTTP/2 will require new best practices for developers to utilize it benefits.&lt;/p&gt;

&lt;h2 id=&quot;multiplexingbinary-framingstream-prioritization&quot;&gt;Multiplexing/Binary Framing/Stream Prioritization&lt;/h2&gt;

&lt;p&gt;First, let’s talk about multiplexing and binary framing. HTTP/2 now technically utilizes a single TLS encrypted connection. While HTTP/1.1 uses a request/response pair, HTTP/2 uses a logical stream. These streams are put into binary frames, encoded in a binary format, and then put on the connection. Streams share the connection and the bandwidth of the connection (multiplexing). If one stream is in a blocking state, this does not prevent other streams from accessing the connection and it’s resources. Additionally, a bonus, the client can specify dependencies and weight for each stream, this is called stream prioritization. But now with HTTP/2 multiple requests for data can be sent in parallel - multiple requests at the same time. HOL blocking is no longer a problem, where it was in HTTP/1.1. Now because requests are cheap, best practices for receiving more out of a request and reduce the number of requests, such as concatenation and spriting, no longer apply.&lt;/p&gt;

&lt;h2 id=&quot;header-compression&quot;&gt;Header Compression&lt;/h2&gt;

&lt;p&gt;Another major issue with HTTP/1.1 pertained to the metadata sent in header. As a result of HTTP being stateless, redundant, long, and static information was sent across each request. One such examples is cookies and user agent data. In addition, the data sent in the headers was in human readable text. These two things combined created the issue of wasted of bandwidth. Developers tried to work around this issue by using gzip to compress the data that goes over the connection. But gzip only compresses the data and not the headers itself. Now with HTTP/2, headers can be compressed because they are seperated from the data. HTTP/2 compresses headers using a new technology specifically for HTTP header compression called HPACK. However with the use of HPACK, compression and decompression works on the connection, meaning more connections are counterproductive. Best practices such as domain sharding and use of multiple origins for cdns are no longer considered best practice for HTTP/2.&lt;/p&gt;

&lt;h2 id=&quot;server-push&quot;&gt;Server Push&lt;/h2&gt;

&lt;p&gt;Lastly, let’s discuss the new push feature. With HTTP/2, the server can respond to a request that hasn’t been sent yet. With this new feature, the server can send any asset or file to the client it thinks it will need. For example, the server can send the css and javascript file because it understands that the client will need it as well after an intial request from the browser is sent for the index.html. Once the client is ready to recieve those files pushed, it will be ready for the client waiting in the cache. Adding further additional optimization of speed.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;To take advantage of the new protocol, there are some new best practices to follow:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reduce DNS Lookups&lt;/li&gt;
  &lt;li&gt;Reuse TCP connections, connections are expensive&lt;/li&gt;
  &lt;li&gt;Use a CDN but reduce the number of origins&lt;/li&gt;
  &lt;li&gt;Minimize number of HTTP redirects&lt;/li&gt;
  &lt;li&gt;Eliminate unnecessary metadata&lt;/li&gt;
  &lt;li&gt;Compress assets during transfer (let gzip compress on the server)&lt;/li&gt;
  &lt;li&gt;Cache resources on the client&lt;/li&gt;
  &lt;li&gt;Eliminate unnecessary resources. Fetch what you need. Bytes are expensive.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As stated previously, since 2015, the world wide web has seen increasing adoption of the new protocol. Companies such as Cloudflare, major hosting providers like Bluehost, and most majors browsers now offer support for the technology. If your site is using a TLS/SSL connection, and your servers from your hosting company support HTTP/2, it is likely that you are already using HTTP/2! Every connection starts out as HTP/1.1 then upgrades to HTTP/2 if all requirements are met. These three requirements must be met to use HTTP/2: (1) Server must support HTTP/2, (2) your application must use an HTTPS connection via TLS/SSL, and (3) the browser of a user must support HTTP/2. If at least one of the requirements are not met, then HTTP/1.1 is used. Developers should be looking to take advantage of the new upgrades provided by HTTP/2 as it’s adoption continues to grow. It’s essentially free optimization for your website!&lt;/p&gt;</content><author><name></name></author><category term="http" /><category term="http/2" /><category term="http/1.1" /><category term="spdy" /><summary type="html">In 2015, the HyperText Transfer Protocol (HTTP) underwent a major revision when HTTP/2 became officially standardized. With the protocol's last major update being in 1999 (HTTP/1.1), it was a much needed upgrade. The previous version of the protocol, HTTP/1.1, proved to posses numerous limitations for most modern websites.</summary></entry></feed>